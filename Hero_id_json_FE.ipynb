{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89836b56ea394d199f780b5dcd36517e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39675), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9fc9f8c265e47d48507c2da5e2effaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3781: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ujson as json\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "#path for loading data, change this as needed\n",
    "PATH = '/Users/m/Insight/MLcourse/Dota/'\n",
    "\n",
    "#json data\n",
    "\n",
    "def read_matches(matches_file):\n",
    "    \n",
    "    MATCHES_COUNT = {\n",
    "        'test_matches.jsonl': 10000,\n",
    "        'train_matches.jsonl': 39675,\n",
    "    }\n",
    "    _, filename = os.path.split(matches_file)\n",
    "    total_matches = MATCHES_COUNT.get(filename)\n",
    "    \n",
    "    with open(matches_file) as fin:\n",
    "        for line in tqdm_notebook(fin, total=total_matches):\n",
    "            yield json.loads(line)\n",
    "            \n",
    "import collections\n",
    "\n",
    "MATCH_FEATURES = [\n",
    "    ('game_time', lambda m: m['game_time']),\n",
    "    ('game_mode', lambda m: m['game_mode']),\n",
    "    ('lobby_type', lambda m: m['lobby_type']),\n",
    "    ('objectives_len', lambda m: len(m['objectives'])),\n",
    "    ('chat_len', lambda m: len(m['chat'])),\n",
    "]\n",
    "\n",
    "PLAYER_FIELDS = [\n",
    "    'hero_id',\n",
    "    \n",
    "    'kills',\n",
    "    'deaths',\n",
    "    'assists',\n",
    "    'denies',\n",
    "    \n",
    "    'gold',\n",
    "    'lh',\n",
    "    'xp',\n",
    "    'health',\n",
    "    'max_health',\n",
    "    'max_mana',\n",
    "    'level',\n",
    "\n",
    "    'x',\n",
    "    'y',\n",
    "    \n",
    "    'stuns',\n",
    "    'creeps_stacked',\n",
    "    'camps_stacked',\n",
    "    'rune_pickups',\n",
    "    'firstblood_claimed',\n",
    "    'teamfight_participation',\n",
    "    'towers_killed',\n",
    "    'roshans_killed',\n",
    "    'obs_placed',\n",
    "    'sen_placed',\n",
    "]\n",
    "\n",
    "def extract_features_csv(match):\n",
    "    row = [\n",
    "        ('match_id_hash', match['match_id_hash']),\n",
    "    ]\n",
    "    \n",
    "    for field, f in MATCH_FEATURES:\n",
    "        row.append((field, f(match)))\n",
    "        \n",
    "    for slot, player in enumerate(match['players']):\n",
    "        if slot < 5:\n",
    "            player_name = 'r%d' % (slot + 1)\n",
    "        else:\n",
    "            player_name = 'd%d' % (slot - 4)\n",
    "\n",
    "        for field in PLAYER_FIELDS:\n",
    "            column_name = '%s_%s' % (player_name, field)\n",
    "            row.append((column_name, player[field]))\n",
    "        row.append((f'{player_name}_ability_level', len(player['ability_upgrades'])))\n",
    "        row.append((f'{player_name}_max_hero_hit', player['max_hero_hit']['value']))\n",
    "        row.append((f'{player_name}_purchase_count', len(player['purchase_log'])))\n",
    "        row.append((f'{player_name}_count_ability_use', sum(player['ability_uses'].values())))\n",
    "        row.append((f'{player_name}_damage_dealt', sum(player['damage'].values())))\n",
    "        row.append((f'{player_name}_damage_received', sum(player['damage_taken'].values())))\n",
    "            \n",
    "    return collections.OrderedDict(row)\n",
    "    \n",
    "def extract_targets_csv(match, targets):\n",
    "    return collections.OrderedDict([('match_id_hash', match['match_id_hash'])] + [\n",
    "        (field, targets[field])\n",
    "        for field in ['game_time', 'radiant_win', 'duration', 'time_remaining', 'next_roshan_team']\n",
    "    ])\n",
    "\n",
    "df_new_features = []\n",
    "df_new_targets = []\n",
    "\n",
    "for match in read_matches(os.path.join(PATH,'train_matches.jsonl')):\n",
    "    match_id_hash = match['match_id_hash']\n",
    "    features = extract_features_csv(match)\n",
    "    targets = extract_targets_csv(match, match['targets'])\n",
    "    \n",
    "    df_new_features.append(features)\n",
    "    df_new_targets.append(targets)\n",
    "\n",
    "df_new_features = pd.DataFrame.from_records(df_new_features).set_index('match_id_hash')\n",
    "df_new_targets = pd.DataFrame.from_records(df_new_targets).set_index('match_id_hash')\n",
    "\n",
    "test_new_features = []\n",
    "for match in read_matches(os.path.join(PATH,'test_matches.jsonl')):\n",
    "    match_id_hash = match['match_id_hash']\n",
    "    features = extract_features_csv(match)\n",
    "    \n",
    "    test_new_features.append(features)\n",
    "test_new_features = pd.DataFrame.from_records(test_new_features).set_index('match_id_hash')\n",
    "\n",
    "train_df = df_new_features\n",
    "test_df = test_new_features\n",
    "train_full = train_df.merge(pd.DataFrame(df_new_targets['radiant_win']),how='outer',left_index=True,right_index=True)\n",
    "\n",
    "\n",
    "#hero id columns names\n",
    "ls_r_hero_id = ['r{}_hero_id'.format(i) for i in range(1,6)]\n",
    "ls_d_hero_id = ['d{}_hero_id'.format(i) for i in range(1,6)]\n",
    "ls_hero_id = ls_r_hero_id + ls_d_hero_id\n",
    "#sub data frame of hero ids and target\n",
    "hero_ids = train_full[ls_hero_id +['radiant_win']]\n",
    "hero_ids_rad_win = hero_ids[hero_ids['radiant_win'] == True] #rad wins\n",
    "hero_ids_rad_lose = hero_ids[hero_ids['radiant_win'] == False] #rad loses\n",
    "winning_hero_ids1 = hero_ids_rad_win[ls_r_hero_id]\n",
    "winning_hero_ids2 = hero_ids_rad_lose[ls_d_hero_id]\n",
    "losing_hero_ids1 = hero_ids_rad_win[ls_d_hero_id]\n",
    "losing_hero_ids2 = hero_ids_rad_lose[ls_r_hero_id]\n",
    "winning_hero_ids1.rename(columns = {'r1_hero_id':'1_id', 'r2_hero_id':'2_id', \n",
    "                              'r3_hero_id':'3_id','r4_hero_id':'4_id',\n",
    "                                    'r5_hero_id':'5_id'}, inplace = True)\n",
    "winning_hero_ids2.rename(columns = {'d1_hero_id':'1_id', 'd2_hero_id':'2_id', \n",
    "                              'd3_hero_id':'3_id','d4_hero_id':'4_id',\n",
    "                                    'd5_hero_id':'5_id'}, inplace = True)\n",
    "losing_hero_ids1.rename(columns = {'d1_hero_id':'1_id', 'd2_hero_id':'2_id', \n",
    "                              'd3_hero_id':'3_id','d4_hero_id':'4_id',\n",
    "                                    'd5_hero_id':'5_id'}, inplace = True)\n",
    "losing_hero_ids2.rename(columns = {'r1_hero_id':'1_id', 'r2_hero_id':'2_id', \n",
    "                              'r3_hero_id':'3_id','r4_hero_id':'4_id',\n",
    "                                    'r5_hero_id':'5_id'}, inplace = True)\n",
    "#for all games, df of winner's hero ids only\n",
    "winning_hero_ids = pd.concat([winning_hero_ids1, winning_hero_ids2], axis=0)\n",
    "#for all games, df of loser's hero ids only\n",
    "losing_hero_ids = pd.concat([losing_hero_ids1, losing_hero_ids2], axis=0)\n",
    "\n",
    "#by hero, in how many games did the hero win / lose\n",
    "winning_hero_counts = winning_hero_ids['1_id'].value_counts().sort_index() + winning_hero_ids['2_id'].value_counts().sort_index() + winning_hero_ids['3_id'].value_counts().sort_index() + winning_hero_ids['4_id'].value_counts().sort_index() + winning_hero_ids['5_id'].value_counts().sort_index()\n",
    "losing_hero_counts = losing_hero_ids['1_id'].value_counts().sort_index() + losing_hero_ids['2_id'].value_counts().sort_index() + losing_hero_ids['3_id'].value_counts().sort_index() + losing_hero_ids['4_id'].value_counts().sort_index() + losing_hero_ids['5_id'].value_counts().sort_index()\n",
    "\n",
    "#to dictionary, key is hero id, value is win / loss count\n",
    "winning_hero_counts = winning_hero_counts.sort_values()\n",
    "winning_hero_dict = winning_hero_counts.to_dict()\n",
    "losing_hero_counts = losing_hero_counts.sort_values()\n",
    "losing_hero_dict = losing_hero_counts.to_dict()\n",
    "\n",
    "#now subtract wins - loses by hero (this will be one feature)\n",
    "hero_counts_win_minus_lose = winning_hero_counts.sort_index() - losing_hero_counts.sort_index()\n",
    "diff_hero_dict = hero_counts_win_minus_lose.to_dict()\n",
    "\n",
    "#normalize by dividing by total number of games played (this is another feature)\n",
    "from collections import Counter\n",
    "total_games_dict = Counter(winning_hero_dict) + Counter(losing_hero_dict)\n",
    "hero_id_normalize_dict = {k: (diff_hero_dict[k] / total_games_dict[k]) for k in diff_hero_dict}\n",
    "\n",
    "#add the two new features to the data frame\n",
    "for col in ls_hero_id:\n",
    "    train_full[col+'success'] = train_full[col].map(diff_hero_dict)\n",
    "    train_df[col+'success'] = train_df[col].map(diff_hero_dict)\n",
    "    test_df[col+'success'] = test_df[col].map(diff_hero_dict)\n",
    "for col in ls_hero_id:\n",
    "    train_full[col+'norm'] = train_full[col].map(hero_id_normalize_dict)\n",
    "    train_df[col+'norm'] = train_df[col].map(hero_id_normalize_dict)\n",
    "    test_df[col+'norm'] = test_df[col].map(hero_id_normalize_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
