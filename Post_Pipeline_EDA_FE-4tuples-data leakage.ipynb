{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi']= 100\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "import ujson as json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "IDs: MB 307; TK 337 \\\n",
    "https://docs.google.com/spreadsheets/d/15e1K0tg5ponA5R6YQkZfihrShTDLAKf5qeKaoVCiuhQ/edit#gid=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Team name, using IDs above: mlcourse_ai_fall2019_team_<id1>_â€¦<id4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.read_csv('/Users/m/Insight/MLcourse/Dota/train_features_plus.csv', index_col='match_id_hash')\n",
    "test_X = pd.read_csv('/Users/m/Insight/MLcourse/Dota/test_features_plus.csv', index_col='match_id_hash')\n",
    "target =  pd.read_csv('/Users/m/Insight/MLcourse/Dota/targets_plus.csv', index_col='match_id_hash')\n",
    "y = target['radiant_win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_ability = pd.read_csv('/Users/m/Insight/MLcourse/Dota/train_features_ability.csv', index_col = 'match_id_hash')\n",
    "test_X_ability = pd.read_csv('/Users/m/Insight/MLcourse/Dota/test_features_ability.csv', index_col = 'match_id_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_X = train_X_old.merge(train_X_ability, how='outer', left_index=True, right_index = True)\n",
    "#test_X = test_X_old.merge(test_X_ability, how='outer', left_index=True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39675, 306)"
      ]
     },
     "execution_count": 835,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = train_X.merge(y, how='outer', left_index=True, right_index=True)\n",
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 305)"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_df['r1_gold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "hero_id_list = ['r1_hero_id','r2_hero_id','r3_hero_id','r4_hero_id',\n",
    "                    'r5_hero_id','d1_hero_id','d2_hero_id','d3_hero_id',\n",
    "                    'd4_hero_id','d5_hero_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hero_ids = full_df[['r1_hero_id','r2_hero_id','r3_hero_id','r4_hero_id',\n",
    "                    'r5_hero_id','d1_hero_id','d2_hero_id','d3_hero_id',\n",
    "                    'd4_hero_id','d5_hero_id','radiant_win']]\n",
    "hero_ids_rad_win = hero_ids[hero_ids['radiant_win'] == True]\n",
    "hero_ids_rad_lose = hero_ids[hero_ids['radiant_win'] == False]\n",
    "#hero_ids_rad_win.shape[0] + hero_ids_rad_lose.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning_hero_ids1 = hero_ids_rad_win[['r1_hero_id','r2_hero_id',\n",
    "                                      'r3_hero_id','r4_hero_id','r5_hero_id']]\n",
    "winning_hero_ids2 = hero_ids_rad_lose[['d1_hero_id','d2_hero_id',\n",
    "                                      'd3_hero_id','d4_hero_id','d5_hero_id']]\n",
    "#winning_hero_ids1.shape[0] + winning_hero_ids2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "losing_hero_ids1 = hero_ids_rad_win[['d1_hero_id','d2_hero_id',\n",
    "                                      'd3_hero_id','d4_hero_id','d5_hero_id']]\n",
    "losing_hero_ids2 = hero_ids_rad_lose[['r1_hero_id','r2_hero_id',\n",
    "                                      'r3_hero_id','r4_hero_id','r5_hero_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning_hero_ids1.rename(columns = {'r1_hero_id':'1_id', 'r2_hero_id':'2_id', \n",
    "                              'r3_hero_id':'3_id','r4_hero_id':'4_id',\n",
    "                                    'r5_hero_id':'5_id'}, inplace = True)\n",
    "winning_hero_ids2.rename(columns = {'d1_hero_id':'1_id', 'd2_hero_id':'2_id', \n",
    "                              'd3_hero_id':'3_id','d4_hero_id':'4_id',\n",
    "                                    'd5_hero_id':'5_id'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "losing_hero_ids1.rename(columns = {'d1_hero_id':'1_id', 'd2_hero_id':'2_id', \n",
    "                              'd3_hero_id':'3_id','d4_hero_id':'4_id',\n",
    "                                    'd5_hero_id':'5_id'}, inplace = True)\n",
    "losing_hero_ids2.rename(columns = {'r1_hero_id':'1_id', 'r2_hero_id':'2_id', \n",
    "                              'r3_hero_id':'3_id','r4_hero_id':'4_id',\n",
    "                                    'r5_hero_id':'5_id'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39675, 5)"
      ]
     },
     "execution_count": 842,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#winning_hero_ids = winning_hero_ids1.merge(winning_hero_ids2, how='outer', \n",
    "#                                           left_index=True, right_index=True)\n",
    "winning_hero_ids = pd.concat([winning_hero_ids1, winning_hero_ids2], axis=0)\n",
    "winning_hero_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39675, 5)"
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losing_hero_ids = pd.concat([losing_hero_ids1, losing_hero_ids2], axis=0)\n",
    "losing_hero_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning_hero_counts = winning_hero_ids['1_id'].value_counts().sort_index() + winning_hero_ids['2_id'].value_counts().sort_index() + winning_hero_ids['3_id'].value_counts().sort_index() + winning_hero_ids['4_id'].value_counts().sort_index() + winning_hero_ids['5_id'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [],
   "source": [
    "losing_hero_counts = losing_hero_ids['1_id'].value_counts().sort_index() + losing_hero_ids['2_id'].value_counts().sort_index() + losing_hero_ids['3_id'].value_counts().sort_index() + losing_hero_ids['4_id'].value_counts().sort_index() + losing_hero_ids['5_id'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning_hero_counts = winning_hero_counts.sort_values()\n",
    "winning_hero_dict = winning_hero_counts.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "losing_hero_counts = losing_hero_counts.sort_values()\n",
    "losing_hero_dict = losing_hero_counts.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "hero_counts_win_minus_lose = winning_hero_counts.sort_index() - losing_hero_counts.sort_index()\n",
    "diff_hero_dict = hero_counts_win_minus_lose.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "total_games_dict = Counter(winning_hero_dict) + Counter(losing_hero_dict)\n",
    "hero_id_normalize_dict = {k: (diff_hero_dict[k] / total_games_dict[k]) for k in diff_hero_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this cell only once! or else NaNs\n",
    "for col in hero_id_list:\n",
    "    full_df[col+'success'] = full_df[col].map(diff_hero_dict)\n",
    "    train_X[col+'success'] = train_X[col].map(diff_hero_dict)\n",
    "    test_X[col+'success'] = test_X[col].map(diff_hero_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run only once!\n",
    "for col in hero_id_list:\n",
    "    full_df[col+'norm'] = full_df[col].map(hero_id_normalize_dict)\n",
    "    train_X[col+'norm'] = train_X[col].map(hero_id_normalize_dict)\n",
    "    test_X[col+'norm'] = test_X[col].map(hero_id_normalize_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39675, 326)"
      ]
     },
     "execution_count": 852,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_X.columns.values == test_X.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 325)"
      ]
     },
     "execution_count": 854,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at hero success, taken k heros per team\n",
    "\n",
    "Heros are numbered from 1 to 120."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k=4 at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_X_old[hero_ids].max()\n",
    "#train_X_old[hero_ids].min()\n",
    "r_hero_ids = hero_id_list[0:5]\n",
    "d_hero_ids = hero_id_list[5:10]\n",
    "hero_ids_num = [i+1 for i in range(120)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "heros_df_r_win = hero_ids[hero_ids['radiant_win']==True]\n",
    "heros_df_r_lose = hero_ids[hero_ids['radiant_win']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_heros_df_r_win = heros_df_r_win[r_hero_ids]\n",
    "r_heros_df_r_lose = heros_df_r_lose[r_hero_ids]\n",
    "d_heros_df_r_win = heros_df_r_win[d_hero_ids]\n",
    "d_heros_df_r_lose = heros_df_r_lose[d_hero_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_heros_df_r_win.values.sort()\n",
    "r_heros_df_r_lose.values.sort()\n",
    "d_heros_df_r_win.values.sort()\n",
    "d_heros_df_r_lose.values.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_4tuple(df,x):\n",
    "    df['{}_hero_4tuple_1'.format(x)] = list(zip(df.iloc[:,0],df.iloc[:,1],df.iloc[:,2],df.iloc[:,3]))\n",
    "    df['{}_hero_4tuple_2'.format(x)] = list(zip(df.iloc[:,1],df.iloc[:,2],df.iloc[:,3],df.iloc[:,4]))\n",
    "    df['{}_hero_4tuple_3'.format(x)] = list(zip(df.iloc[:,0],df.iloc[:,1],df.iloc[:,3],df.iloc[:,4]))\n",
    "    df['{}_hero_4tuple_4'.format(x)] = list(zip(df.iloc[:,0],df.iloc[:,1],df.iloc[:,2],df.iloc[:,4]))\n",
    "    df['{}_hero_4tuple_5'.format(x)] = list(zip(df.iloc[:,0],df.iloc[:,2],df.iloc[:,3],df.iloc[:,4]))\n",
    "    df = df[df.columns[-5:]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_heros_df_r_win = make_4tuple(r_heros_df_r_win,'r');\n",
    "r_heros_df_r_lose = make_4tuple(r_heros_df_r_lose,'r');\n",
    "d_heros_df_r_win = make_4tuple(d_heros_df_r_win,'d');\n",
    "d_heros_df_r_lose = make_4tuple(d_heros_df_r_lose,'d');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['d_hero_4tuple_1', 'd_hero_4tuple_2', 'd_hero_4tuple_3',\n",
       "       'd_hero_4tuple_4', 'd_hero_4tuple_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_heros_df_r_lose.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_cols_r = ['r_hero_4tuple_1','r_hero_4tuple_2','r_hero_4tuple_3','r_hero_4tuple_4','r_hero_4tuple_5']\n",
    "tuple_cols_d = ['d_hero_4tuple_1','d_hero_4tuple_2','d_hero_4tuple_3','d_hero_4tuple_4','d_hero_4tuple_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_4heros = {}\n",
    "for i in range(r_heros_df_r_win.shape[0]):\n",
    "    for j in tuple_cols_r:\n",
    "        if r_heros_df_r_win[j].iloc[i] not in dict_4heros:\n",
    "            dict_4heros[r_heros_df_r_win[j].iloc[i]] = 1\n",
    "        else:\n",
    "            dict_4heros[r_heros_df_r_win[j].iloc[i]] +=1\n",
    "for i in range(r_heros_df_r_lose.shape[0]):\n",
    "    for j in tuple_cols_r:\n",
    "        if r_heros_df_r_lose[j].iloc[i] not in dict_4heros:\n",
    "            dict_4heros[r_heros_df_r_lose[j].iloc[i]] = -1\n",
    "        else:\n",
    "            dict_4heros[r_heros_df_r_lose[j].iloc[i]] += -1\n",
    "for i in range(d_heros_df_r_win.shape[0]):\n",
    "    for j in tuple_cols_d:\n",
    "        if d_heros_df_r_win[j].iloc[i] not in dict_4heros:\n",
    "            dict_4heros[d_heros_df_r_win[j].iloc[i]] = 1\n",
    "        else:\n",
    "            dict_4heros[d_heros_df_r_win[j].iloc[i]] += -1\n",
    "for i in range(d_heros_df_r_lose.shape[0]):\n",
    "    for j in tuple_cols_d:\n",
    "        if d_heros_df_r_lose[j].iloc[i] not in dict_4heros:\n",
    "            dict_4heros[d_heros_df_r_lose[j].iloc[i]] = -1\n",
    "        else:\n",
    "            dict_4heros[d_heros_df_r_lose[j].iloc[i]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max(dict_4heros.values())\n",
    "#min(dict_4heros.values())\n",
    "#dict_4heros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat 4 data frames, then append new columns to full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_win = r_heros_df_r_win.merge(d_heros_df_r_win,how='outer',left_index=True,right_index=True)\n",
    "d_win = r_heros_df_r_lose.merge(d_heros_df_r_lose,how='outer',left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20826, 10)\n",
      "(18849, 10)\n"
     ]
    }
   ],
   "source": [
    "print(r_win.shape)\n",
    "print(d_win.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_win.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r_hero_4tuple_1</th>\n",
       "      <th>r_hero_4tuple_2</th>\n",
       "      <th>r_hero_4tuple_3</th>\n",
       "      <th>r_hero_4tuple_4</th>\n",
       "      <th>r_hero_4tuple_5</th>\n",
       "      <th>d_hero_4tuple_1</th>\n",
       "      <th>d_hero_4tuple_2</th>\n",
       "      <th>d_hero_4tuple_3</th>\n",
       "      <th>d_hero_4tuple_4</th>\n",
       "      <th>d_hero_4tuple_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match_id_hash</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b9c57c450ce74a2af79c9ce96fac144d</th>\n",
       "      <td>(15, 27, 63, 89)</td>\n",
       "      <td>(27, 63, 89, 96)</td>\n",
       "      <td>(15, 27, 89, 96)</td>\n",
       "      <td>(15, 27, 63, 96)</td>\n",
       "      <td>(15, 63, 89, 96)</td>\n",
       "      <td>(1, 14, 56, 58)</td>\n",
       "      <td>(14, 56, 58, 92)</td>\n",
       "      <td>(1, 14, 58, 92)</td>\n",
       "      <td>(1, 14, 56, 92)</td>\n",
       "      <td>(1, 56, 58, 92)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   r_hero_4tuple_1   r_hero_4tuple_2  \\\n",
       "match_id_hash                                                          \n",
       "b9c57c450ce74a2af79c9ce96fac144d  (15, 27, 63, 89)  (27, 63, 89, 96)   \n",
       "\n",
       "                                   r_hero_4tuple_3   r_hero_4tuple_4  \\\n",
       "match_id_hash                                                          \n",
       "b9c57c450ce74a2af79c9ce96fac144d  (15, 27, 89, 96)  (15, 27, 63, 96)   \n",
       "\n",
       "                                   r_hero_4tuple_5  d_hero_4tuple_1  \\\n",
       "match_id_hash                                                         \n",
       "b9c57c450ce74a2af79c9ce96fac144d  (15, 63, 89, 96)  (1, 14, 56, 58)   \n",
       "\n",
       "                                   d_hero_4tuple_2  d_hero_4tuple_3  \\\n",
       "match_id_hash                                                         \n",
       "b9c57c450ce74a2af79c9ce96fac144d  (14, 56, 58, 92)  (1, 14, 58, 92)   \n",
       "\n",
       "                                  d_hero_4tuple_4  d_hero_4tuple_5  \n",
       "match_id_hash                                                       \n",
       "b9c57c450ce74a2af79c9ce96fac144d  (1, 14, 56, 92)  (1, 56, 58, 92)  "
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no longer needed\n",
    "#list_to_drop = ['r{}_hero_id'.format(i) for i in range(1,6)] + ['d{}_hero_id'.format(i) for i in range(1,6)]\n",
    "#r_win.drop(list_to_drop,axis=1,inplace=True)\n",
    "#r_win.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d_win.drop(list_to_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['r_hero_4tuple_1', 'r_hero_4tuple_2', 'r_hero_4tuple_3',\n",
       "       'r_hero_4tuple_4', 'r_hero_4tuple_5', 'd_hero_4tuple_1',\n",
       "       'd_hero_4tuple_2', 'd_hero_4tuple_3', 'd_hero_4tuple_4',\n",
       "       'd_hero_4tuple_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple_cols = tuple_cols_r + tuple_cols_d\n",
    "four_tuples = pd.concat([r_win,d_win])\n",
    "four_tuples.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39675, 326)"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_plus4tuple = pd.concat([full_df,four_tuples], axis=1)\n",
    "train_X_plus4tuple = pd.concat([train_X,four_tuples],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39675, 335)"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df_plus4tuple.shape\n",
    "train_X_plus4tuple.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(full_df_plus4tuple.columns.values).difference(set(full_df.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run only once or else nans\n",
    "for col in tuple_cols:\n",
    "    full_df_plus4tuple[col+'_map'] = full_df_plus4tuple[col].map(dict_4heros)\n",
    "    train_X_plus4tuple[col+'_map'] = train_X_plus4tuple[col].map(dict_4heros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_plus4tuple.drop(tuple_cols,inplace=True,axis=1)\n",
    "train_X_plus4tuple.drop(tuple_cols,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df_plus4tuple\n",
    "train_X = train_X_plus4tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39675, 336)"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39675, 335)"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_X.columns.values).difference(set(test_X_plus_4tuple.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map `dict_4heros` to `test_X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(full_df.columns.values).difference(set(test_X_plus_4tuple.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(test_X_plus_4tuple.columns.values).difference(set(full_df.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_hero_cols =['r{}_hero_id'.format(i) for i in range(1,6)]\n",
    "d_hero_cols =['d{}_hero_id'.format(i) for i in range(1,6)]\n",
    "test_X_r_heros = test_X[r_hero_cols]\n",
    "test_X_d_heros = test_X[d_hero_cols]\n",
    "test_X_r_heros.values.sort()\n",
    "test_X_d_heros.values.sort()\n",
    "make_4tuple(test_X_r_heros,'r');\n",
    "make_4tuple(test_X_d_heros,'d');\n",
    "for col in tuple_cols_r:\n",
    "    test_X_r_heros[col+'_map'] = test_X_r_heros[col].map(dict_4heros)\n",
    "for col in tuple_cols_d:\n",
    "    test_X_d_heros[col+'_map'] = test_X_d_heros[col].map(dict_4heros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_d_heros.fillna(0,inplace=True)\n",
    "test_X_r_heros.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['d1_hero_id', 'd2_hero_id', 'd3_hero_id', 'd4_hero_id', 'd5_hero_id',\n",
       "       'd_hero_4tuple_1', 'd_hero_4tuple_2', 'd_hero_4tuple_3',\n",
       "       'd_hero_4tuple_4', 'd_hero_4tuple_5', 'd_hero_4tuple_1_map',\n",
       "       'd_hero_4tuple_2_map', 'd_hero_4tuple_3_map', 'd_hero_4tuple_4_map',\n",
       "       'd_hero_4tuple_5_map'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X_d_heros.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "hero_id_list_d = ['d{}_hero_id'.format(i) for i in range(1,6)] \n",
    "hero_id_list_r =['r{}_hero_id'.format(i) for i in range(1,6)] \n",
    "test_X_d_heros.drop(hero_id_list_d,inplace=True,axis=1)\n",
    "test_X_r_heros.drop(hero_id_list_r,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_cols_d_map = ['d_hero_4tuple_{}_map'.format(i) for i in range(1,6)] \n",
    "tuple_cols_r_map =['r_hero_4tuple_{}_map'.format(i) for i in range(1,6)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_plus_4tuple = pd.concat([test_X,test_X_d_heros[tuple_cols_d_map]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_plus_4tuple = pd.concat([test_X_plus_4tuple,test_X_r_heros[tuple_cols_r_map]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39675, 336)"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 335)"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X_plus_4tuple.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_X_plus_4tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.drop(hero_id_list,inplace=True,axis=1)\n",
    "train_X.drop(hero_id_list,inplace=True,axis=1)\n",
    "test_X.drop(hero_id_list,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#same columns\n",
    "set(full_df.columns.values).difference(set(train_X.columns.values))\n",
    "set(train_X.columns.values).difference(set(full_df.columns.values))\n",
    "set(test_X.columns.values).difference(set(train_X.columns.values))\n",
    "set(train_X.columns.values).difference(set(test_X.columns.values))\n",
    "set(full_df.columns.values).difference(set(test_X.columns.values))\n",
    "set(test_X.columns.values).difference(set(full_df.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_hero_ids_by2 = list(itertools.combinations(r_hero_ids, 2))\n",
    "d_hero_ids_by2 = list(itertools.combinations(d_hero_ids, 2))\n",
    "hero_ids_by2 = list(itertools.combinations(hero_ids_num,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_hero_cols = []\n",
    "for i in range(1,6):\n",
    "    for j in range(i+1,6):\n",
    "        new_hero_cols.append('r'+str(i)+'_'+str(j))\n",
    "for i in range(1,6):\n",
    "    for j in range(i+1,6):\n",
    "        new_hero_cols.append('d'+str(i)+'_'+str(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "metadata": {},
   "outputs": [],
   "source": [
    "hero_by2_dict_win = {k:0 for k in hero_ids_by2}\n",
    "for i in range(r_heros_df_rad_win.shape[0]):\n",
    "    for j in range(r_heros_df_rad_win.shape[1]):\n",
    "        for k in range(j+1,r_heros_df_rad_win.shape[1]):\n",
    "            Key = (r_heros_df_rad_win.iloc[i,j],r_heros_df_rad_win.iloc[i,k])\n",
    "            hero_by2_dict_win[Key] +=1\n",
    "for i in range(d_heros_df_rad_win.shape[0]):\n",
    "    for j in range(d_heros_df_rad_win.shape[1]):\n",
    "        for k in range(j+1,d_heros_df_rad_win.shape[1]):\n",
    "            Key = (d_heros_df_rad_win.iloc[i,j],d_heros_df_rad_win.iloc[i,k])\n",
    "            hero_by2_dict_win[Key] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {},
   "outputs": [],
   "source": [
    "hero_by2_dict_lose = {k:0 for k in hero_ids_by2}\n",
    "for i in range(r_heros_df_rad_lose.shape[0]):\n",
    "    for j in range(r_heros_df_rad_lose.shape[1]):\n",
    "        for k in range(j+1,r_heros_df_rad_lose.shape[1]):\n",
    "            Key = (r_heros_df_rad_lose.iloc[i,j],r_heros_df_rad_lose.iloc[i,k])\n",
    "            hero_by2_dict_lose[Key] +=1\n",
    "for i in range(d_heros_df_rad_lose.shape[0]):\n",
    "    for j in range(d_heros_df_rad_lose.shape[1]):\n",
    "        for k in range(j+1,d_heros_df_rad_lose.shape[1]):\n",
    "            Key = (d_heros_df_rad_lose.iloc[i,j],d_heros_df_rad_lose.iloc[i,k])\n",
    "            hero_by2_dict_lose[Key] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = Counter(hero_by2_dict_win)\n",
    "d2 = Counter(hero_by2_dict_lose)\n",
    "d1.subtract(d2)\n",
    "hero_by2_dict_net = d1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now data frames have each row of hero ids sorted least to greatest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r1_2',\n",
       " 'r1_3',\n",
       " 'r1_4',\n",
       " 'r1_5',\n",
       " 'r2_3',\n",
       " 'r2_4',\n",
       " 'r2_5',\n",
       " 'r3_4',\n",
       " 'r3_5',\n",
       " 'r4_5',\n",
       " 'd1_2',\n",
       " 'd1_3',\n",
       " 'd1_4',\n",
       " 'd1_5',\n",
       " 'd2_3',\n",
       " 'd2_4',\n",
       " 'd2_5',\n",
       " 'd3_4',\n",
       " 'd3_5',\n",
       " 'd4_5']"
      ]
     },
     "execution_count": 958,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_hero_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_2_heros(game):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also add feature of normalized hero id (divide by total games for each hero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now have mapped hero id's to how often they participate in winning games, so will now be a numeric feature and can also use sum of this as a new feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using json files for new features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH_TO_DATA, 'train_matches.jsonl')) as fin:\n",
    "    # read the 18-th line\n",
    "    for i in range(18):\n",
    "        line = fin.readline()\n",
    "    \n",
    "    # read JSON into a Python object \n",
    "    match = json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['game_time', 'match_id_hash', 'teamfights', 'objectives', 'chat', 'game_mode', 'lobby_type', 'players', 'targets'])"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with ability upgrades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a single match, test new features:\n",
    "`max_ability_dt`\n",
    "`min_ability_dt`\n",
    "`mean_ability_dt`\n",
    "`max_ability_da`\n",
    "`min_ability_da`\n",
    "`mean_ability_da`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 120.5625 227 1929\n",
      "-1352 314.5625 5032 5033\n"
     ]
    }
   ],
   "source": [
    "player = match['players'][2]\n",
    "n = len(player['ability_upgrades'])\n",
    "first_ability_time = player['ability_upgrades'][0]['time']\n",
    "last_ability_time = player['ability_upgrades'][n-1]['time']\n",
    "ability_dt = [first_ability_time]\n",
    "#time differences between level changes\n",
    "for i in range(n-1):\n",
    "    diff = player['ability_upgrades'][i+1]['time'] - player['ability_upgrades'][i]['time']\n",
    "    ability_dt.append(diff)\n",
    "min_ability_dt = min(ability_dt)\n",
    "max_ability_dt = max(ability_dt)\n",
    "mean_ability_dt = sum(ability_dt)/len(ability_dt)\n",
    "print(min_ability_dt,mean_ability_dt,max_ability_dt,last_ability_time)\n",
    "#ability differences between level changes\n",
    "ability_d_ability = [player['ability_upgrades'][0]['ability']]\n",
    "last_ability = player['ability_upgrades'][n-1]['ability']\n",
    "for i in range(n-1):\n",
    "    diff = player['ability_upgrades'][i+1]['ability'] - player['ability_upgrades'][i]['ability']\n",
    "    ability_d_ability.append(diff)\n",
    "min_ability_d_ability = min(ability_d_ability)\n",
    "max_ability_d_ability = max(ability_d_ability)\n",
    "mean_ability_d_ability = sum(ability_d_ability)/len(ability_d_ability)\n",
    "print(min_ability_d_ability,mean_ability_d_ability,max_ability_d_ability,last_ability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "#player['ability_upgrades']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_matches(matches_file):\n",
    "    \n",
    "    MATCHES_COUNT = {\n",
    "        'test_matches.jsonl': 10000,\n",
    "        'train_matches.jsonl': 39675,\n",
    "    }\n",
    "    _, filename = os.path.split(matches_file)\n",
    "    total_matches = MATCHES_COUNT.get(filename)\n",
    "    \n",
    "    with open(matches_file) as fin:\n",
    "        for line in tqdm_notebook(fin, total=total_matches):\n",
    "            yield json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_file = '/Users/m/Insight/MLcourse/Dota/train_matches.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_csv(match):\n",
    "    row = [\n",
    "        ('match_id_hash', match['match_id_hash']),\n",
    "    ]\n",
    "    \n",
    "    for slot, player in enumerate(match['players']):\n",
    "        if slot < 5:\n",
    "            player_name = 'r%d' % (slot + 1)\n",
    "        else:\n",
    "            player_name = 'd%d' % (slot - 4)\n",
    "            \n",
    "        n = len(player['ability_upgrades'])\n",
    "        if n > 0:    \n",
    "            first_ability_time = player['ability_upgrades'][0]['time']\n",
    "            row.append((f'{player_name}_first_ability_t', first_ability_time))\n",
    "            last_ability_time = player['ability_upgrades'][n-1]['time']\n",
    "            row.append((f'{player_name}_last_ability_t', last_ability_time))\n",
    "            ability_dt = [first_ability_time]\n",
    "            #time differences between level changes\n",
    "            for i in range(n-1):\n",
    "                diff = player['ability_upgrades'][i+1]['time'] - player['ability_upgrades'][i]['time']\n",
    "                ability_dt.append(diff)\n",
    "            min_ability_dt = min(ability_dt)\n",
    "            row.append((f'{player_name}_min_ability_dt', min_ability_dt))\n",
    "            max_ability_dt = max(ability_dt)\n",
    "            row.append((f'{player_name}_max_ability_dt', max_ability_dt))\n",
    "            mean_ability_dt = sum(ability_dt)/len(ability_dt)\n",
    "            row.append((f'{player_name}_mean_ability_dt', mean_ability_dt))\n",
    "\n",
    "            #ability differences between level changes\n",
    "            first_ability = player['ability_upgrades'][0]['ability']\n",
    "            row.append((f'{player_name}_first_ability', first_ability))\n",
    "            last_ability = player['ability_upgrades'][n-1]['ability']\n",
    "            row.append((f'{player_name}_last_ability', last_ability))\n",
    "            dability = []\n",
    "            for i in range(n-1):\n",
    "                diff = player['ability_upgrades'][i+1]['ability'] - player['ability_upgrades'][i]['ability']\n",
    "                dability.append(diff)\n",
    "            try:\n",
    "                min_ability_da = min(dability)\n",
    "            except:\n",
    "                min_ability_da = 0\n",
    "            row.append((f'{player_name}_min_ability_da', min_ability_da))\n",
    "            try:\n",
    "                max_ability_da = max(dability)\n",
    "            except:\n",
    "                max_ability_da = 0\n",
    "            row.append((f'{player_name}_max_ability_da', max_ability_da))\n",
    "            try:\n",
    "                mean_ability_da = sum(dability)/len(dability)\n",
    "            except:\n",
    "                mean_ability_da = 0\n",
    "            row.append((f'{player_name}_mean_ability_da', mean_ability_da))\n",
    "        else:\n",
    "            row.append((f'{player_name}_first_ability_t', 0))\n",
    "            row.append((f'{player_name}_last_ability_t', 0))\n",
    "            row.append((f'{player_name}_min_ability_dt', 0))\n",
    "            row.append((f'{player_name}_max_ability_dt', 0))\n",
    "            row.append((f'{player_name}_mean_ability_dt', 0))\n",
    "\n",
    "            row.append((f'{player_name}_first_ability', 0))\n",
    "            row.append((f'{player_name}_last_ability', 0))\n",
    "            row.append((f'{player_name}_min_ability_da', 0))\n",
    "            row.append((f'{player_name}_max_ability_da', 0))\n",
    "            row.append((f'{player_name}_mean_ability_da', 0))\n",
    "    \n",
    "    return collections.OrderedDict(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc09c11723540148ee54888a4410c25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39675), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "json_feats = []\n",
    "for match in read_matches(matches_file):\n",
    "    match_id_hash = match['match_id_hash']\n",
    "    features = extract_features_csv(match)\n",
    "    json_feats.append(features)\n",
    "df_json_feats = pd.DataFrame(json_feats).set_index('match_id_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export_csv = df_json_feats.to_csv(r'/Users/m/Insight/MLcourse/Dota/train_features_ability.csv', index = 'match_id_hash', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_file_test = '/Users/m/Insight/MLcourse/Dota/test_matches.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f895bafcfda4ed08a8ef6f4415dc89d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "json_feats_test = []\n",
    "for match in read_matches(matches_file_test):\n",
    "    match_id_hash = match['match_id_hash']\n",
    "    features = extract_features_csv(match)\n",
    "    json_feats_test.append(features)\n",
    "df_json_feats_test = pd.DataFrame(json_feats_test).set_index('match_id_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export_csv_test = df_json_feats_test.to_csv(r'/Users/m/Insight/MLcourse/Dota/test_features_ability.csv', index = 'match_id_hash', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 767,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test on a few features\n",
    "matches = []\n",
    "\n",
    "with open(os.path.join('/Users/m/Insight/MLcourse/Dota/train_matches.jsonl')) as fin:\n",
    "    for j in range(5):\n",
    "        for i in range(j):\n",
    "            line = fin.readline()\n",
    "\n",
    "        # read JSON into a Python object \n",
    "        matches.append(json.loads(line))\n",
    "\n",
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r1_first_ability_t</th>\n",
       "      <th>r1_last_ability_t</th>\n",
       "      <th>r1_min_ability_dt</th>\n",
       "      <th>r1_max_ability_dt</th>\n",
       "      <th>r1_mean_ability_dt</th>\n",
       "      <th>r1_first_ability</th>\n",
       "      <th>r1_last_ability</th>\n",
       "      <th>r1_min_ability_da</th>\n",
       "      <th>r1_max_ability_da</th>\n",
       "      <th>r1_mean_ability_da</th>\n",
       "      <th>...</th>\n",
       "      <th>d5_first_ability_t</th>\n",
       "      <th>d5_last_ability_t</th>\n",
       "      <th>d5_min_ability_dt</th>\n",
       "      <th>d5_max_ability_dt</th>\n",
       "      <th>d5_mean_ability_dt</th>\n",
       "      <th>d5_first_ability</th>\n",
       "      <th>d5_last_ability</th>\n",
       "      <th>d5_min_ability_da</th>\n",
       "      <th>d5_max_ability_da</th>\n",
       "      <th>d5_mean_ability_da</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match_id_hash</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7469e9440ea3d19b211a484647c7126e</th>\n",
       "      <td>230</td>\n",
       "      <td>984</td>\n",
       "      <td>76</td>\n",
       "      <td>262</td>\n",
       "      <td>164.0</td>\n",
       "      <td>5353</td>\n",
       "      <td>5356</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>228</td>\n",
       "      <td>1033</td>\n",
       "      <td>47</td>\n",
       "      <td>228</td>\n",
       "      <td>103.3</td>\n",
       "      <td>5098</td>\n",
       "      <td>6926</td>\n",
       "      <td>-2</td>\n",
       "      <td>1828</td>\n",
       "      <td>203.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a400b8f29dece5f4d266f49f1ae2e98a</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6db558535151ea18ca70a6892197db41</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19c39fe2af2b547e48708ca005c6ae74</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7469e9440ea3d19b211a484647c7126e</th>\n",
       "      <td>230</td>\n",
       "      <td>984</td>\n",
       "      <td>76</td>\n",
       "      <td>262</td>\n",
       "      <td>164.0</td>\n",
       "      <td>5353</td>\n",
       "      <td>5356</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>228</td>\n",
       "      <td>1033</td>\n",
       "      <td>47</td>\n",
       "      <td>228</td>\n",
       "      <td>103.3</td>\n",
       "      <td>5098</td>\n",
       "      <td>6926</td>\n",
       "      <td>-2</td>\n",
       "      <td>1828</td>\n",
       "      <td>203.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  r1_first_ability_t  r1_last_ability_t  \\\n",
       "match_id_hash                                                             \n",
       "7469e9440ea3d19b211a484647c7126e                 230                984   \n",
       "a400b8f29dece5f4d266f49f1ae2e98a                   0                  0   \n",
       "6db558535151ea18ca70a6892197db41                   0                  0   \n",
       "19c39fe2af2b547e48708ca005c6ae74                   0                  0   \n",
       "7469e9440ea3d19b211a484647c7126e                 230                984   \n",
       "\n",
       "                                  r1_min_ability_dt  r1_max_ability_dt  \\\n",
       "match_id_hash                                                            \n",
       "7469e9440ea3d19b211a484647c7126e                 76                262   \n",
       "a400b8f29dece5f4d266f49f1ae2e98a                  0                  0   \n",
       "6db558535151ea18ca70a6892197db41                  0                  0   \n",
       "19c39fe2af2b547e48708ca005c6ae74                  0                  0   \n",
       "7469e9440ea3d19b211a484647c7126e                 76                262   \n",
       "\n",
       "                                  r1_mean_ability_dt  r1_first_ability  \\\n",
       "match_id_hash                                                            \n",
       "7469e9440ea3d19b211a484647c7126e               164.0              5353   \n",
       "a400b8f29dece5f4d266f49f1ae2e98a                 0.0                 0   \n",
       "6db558535151ea18ca70a6892197db41                 0.0                 0   \n",
       "19c39fe2af2b547e48708ca005c6ae74                 0.0                 0   \n",
       "7469e9440ea3d19b211a484647c7126e               164.0              5353   \n",
       "\n",
       "                                  r1_last_ability  r1_min_ability_da  \\\n",
       "match_id_hash                                                          \n",
       "7469e9440ea3d19b211a484647c7126e             5356                 -2   \n",
       "a400b8f29dece5f4d266f49f1ae2e98a                0                  0   \n",
       "6db558535151ea18ca70a6892197db41                0                  0   \n",
       "19c39fe2af2b547e48708ca005c6ae74                0                  0   \n",
       "7469e9440ea3d19b211a484647c7126e             5356                 -2   \n",
       "\n",
       "                                  r1_max_ability_da  r1_mean_ability_da  ...  \\\n",
       "match_id_hash                                                            ...   \n",
       "7469e9440ea3d19b211a484647c7126e                  2                 0.6  ...   \n",
       "a400b8f29dece5f4d266f49f1ae2e98a                  0                 0.0  ...   \n",
       "6db558535151ea18ca70a6892197db41                  0                 0.0  ...   \n",
       "19c39fe2af2b547e48708ca005c6ae74                  0                 0.0  ...   \n",
       "7469e9440ea3d19b211a484647c7126e                  2                 0.6  ...   \n",
       "\n",
       "                                  d5_first_ability_t  d5_last_ability_t  \\\n",
       "match_id_hash                                                             \n",
       "7469e9440ea3d19b211a484647c7126e                 228               1033   \n",
       "a400b8f29dece5f4d266f49f1ae2e98a                   0                  0   \n",
       "6db558535151ea18ca70a6892197db41                   0                  0   \n",
       "19c39fe2af2b547e48708ca005c6ae74                   0                  0   \n",
       "7469e9440ea3d19b211a484647c7126e                 228               1033   \n",
       "\n",
       "                                  d5_min_ability_dt  d5_max_ability_dt  \\\n",
       "match_id_hash                                                            \n",
       "7469e9440ea3d19b211a484647c7126e                 47                228   \n",
       "a400b8f29dece5f4d266f49f1ae2e98a                  0                  0   \n",
       "6db558535151ea18ca70a6892197db41                  0                  0   \n",
       "19c39fe2af2b547e48708ca005c6ae74                  0                  0   \n",
       "7469e9440ea3d19b211a484647c7126e                 47                228   \n",
       "\n",
       "                                  d5_mean_ability_dt  d5_first_ability  \\\n",
       "match_id_hash                                                            \n",
       "7469e9440ea3d19b211a484647c7126e               103.3              5098   \n",
       "a400b8f29dece5f4d266f49f1ae2e98a                 0.0                 0   \n",
       "6db558535151ea18ca70a6892197db41                 0.0                 0   \n",
       "19c39fe2af2b547e48708ca005c6ae74                 0.0                 0   \n",
       "7469e9440ea3d19b211a484647c7126e               103.3              5098   \n",
       "\n",
       "                                  d5_last_ability  d5_min_ability_da  \\\n",
       "match_id_hash                                                          \n",
       "7469e9440ea3d19b211a484647c7126e             6926                 -2   \n",
       "a400b8f29dece5f4d266f49f1ae2e98a                0                  0   \n",
       "6db558535151ea18ca70a6892197db41                0                  0   \n",
       "19c39fe2af2b547e48708ca005c6ae74                0                  0   \n",
       "7469e9440ea3d19b211a484647c7126e             6926                 -2   \n",
       "\n",
       "                                  d5_max_ability_da  d5_mean_ability_da  \n",
       "match_id_hash                                                            \n",
       "7469e9440ea3d19b211a484647c7126e               1828          203.111111  \n",
       "a400b8f29dece5f4d266f49f1ae2e98a                  0            0.000000  \n",
       "6db558535151ea18ca70a6892197db41                  0            0.000000  \n",
       "19c39fe2af2b547e48708ca005c6ae74                  0            0.000000  \n",
       "7469e9440ea3d19b211a484647c7126e               1828          203.111111  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_feats = []\n",
    "for match in matches:\n",
    "    match_id_hash = match['match_id_hash']\n",
    "    features = extract_features_csv(match)\n",
    "    json_feats.append(features)\n",
    "DF = pd.DataFrame(json_feats).set_index('match_id_hash')\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find new features:\n",
    "\n",
    "1. Use data from `match['teamfights']`. This could be hard because nothing specific here about  teams, would have to link teamfights to players.\n",
    "2. Hero data:\n",
    "Find best hero combinations for winning games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 325)"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39675, 325)"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39675, 326)"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49675, 325)"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_feat = pd.concat([full_df.drop('radiant_win',axis=1),test_X])\n",
    "train_test_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 741,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_test_feat.columns.values).difference(set(full_df.columns.values))\n",
    "set(train_X.columns.values).difference(set(train_test_feat.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_cols_n_distinct(data,min,max):\n",
    "    '''select columns in data frame with number of \n",
    "    distinct values between min and max, inclusive'''\n",
    "    cols = []\n",
    "    for col in data.columns.values:\n",
    "        unique_vals = data[col].value_counts().shape[0]\n",
    "        if unique_vals >= min and unique_vals <= max:\n",
    "            #cols.append((col,unique_vals))\n",
    "            cols.append(col)\n",
    "    return cols    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "select_cols_n_distinct(full_df.drop('radiant_win',axis=1),2,2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiant_win_T = full_df[full_df['radiant_win'] == 1]['lobby_type']\n",
    "radiant_win_F = full_df[full_df['radiant_win'] == 0]['lobby_type']\n",
    "#sns.distplot(radiant_win_T, bins=100, label='R won')\n",
    "#sns.distplot(radiant_win_F, bins=100, label='R lost')\n",
    "#plt.xlim(1900, 2020)\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.countplot(x=\"lobby_type\", hue=\"radiant_win\", data=full_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = pd.DataFrame(index=train_test_feat.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = [i.replace(\"1\",\"\")  for i in full_df.columns.values if (i.startswith('r1')==1 \n",
    "                                                                    or i.startswith('d1')==1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a feature that is sum of r1 + ... + r5 for all r features, and same for all d features. Note that not all of these make sense, so some should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in new_feats:\n",
    "    feat_names = [(feature[0] + '{}_'.format(i) +feature[2:]) for i in range(1,6)]\n",
    "    new_features[feature] = train_test_feat.loc[:,feat_names].sum(axis=1)\n",
    "   # new_features[feature + '_mean'] = train_test_feat.loc[:,feat_names].mean(axis=1)\n",
    "   #new_features[feature + '_std'] = train_test_feat.loc[:,feat_names].std(axis=1)\n",
    "#new_features.drop(['r_hero_id','d_hero_id'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_features.columns)\n",
    "#new_features.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New features from TK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "health = ['r{}_health'.format(x) for x in range(1,6)] +['d{}_health'.format(x) for x in range(1,6)]\n",
    "max_health = ['r{}_health'.format(x) for x in range(1,6)] +['d{}_health'.format(x) for x in range(1,6)]\n",
    "x = ['r{}_x'.format(x) for x in range(1,6)] +['d{}_x'.format(x) for x in range(1,6)]\n",
    "y1 = ['r{}_y'.format(x) for x in range(1,6)] +['d{}_y'.format(x) for x in range(1,6)]\n",
    "xp = ['r{}_xp'.format(x) for x in range(1,6)] +['d{}_xp'.format(x) for x in range(1,6)]\n",
    "\n",
    "train_positions = train_X[health+max_health+x+y1+xp]\n",
    "#train_positions.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_dead(x):\n",
    "    ans = 0 \n",
    "    for el in x:\n",
    "        if el == 0:\n",
    "            ans += 1\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_health = ['d{}_health'.format(i) for i in range(1,6)]\n",
    "new_features['d_dead'] = full_df[d_health].apply(are_dead, axis = 1)\n",
    "r_health = ['r{}_health'.format(i) for i in range(1,6)]\n",
    "new_features['r_dead'] = full_df[r_health].apply(are_dead, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_health = 0\n",
    "for j in range(5):\n",
    "    max_health = '{}_max_health'.format(d_health[j].split('_')[0])\n",
    "    health = 'd{}_health'.format(j+1)\n",
    "    ph = full_df[health]/full_df[max_health]\n",
    "    percentage_health += 1/5*ph\n",
    "\n",
    "new_features['d_health_avg'] = percentage_health\n",
    "\n",
    "percentage_health = 0\n",
    "for j in range(5):\n",
    "    max_health = '{}_max_health'.format(r_health[j].split('_')[0])\n",
    "    health = 'r{}_health'.format(j+1)\n",
    "    ph = full_df[health]/full_df[max_health]\n",
    "    percentage_health += 1/5*ph\n",
    "\n",
    "new_features['r_health_avg'] = percentage_health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def in_opponent_base(x,y,opponent = 'Radiant'):\n",
    "\n",
    "    '''\n",
    "returns indicator function of whether the player is in the base of the opponent\n",
    "opponent = {'Radiant', 'Dire'} - opponent team\n",
    "    \n",
    "    '''\n",
    "#     x = coordinates[0]\n",
    "#     y = coordinates[1]\n",
    "    radiant_base_x = 96\n",
    "    radiant_base_y = 100\n",
    "\n",
    "    dire_base_x = 156\n",
    "    dire_base_y = 156\n",
    "\n",
    "    if opponent == 'Radiant':\n",
    "        if x <= radiant_base_x and y <= radiant_base_y:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    elif opponent == 'Dire':\n",
    "        if x >= dire_base_x and y >= dire_base_y:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return NaN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "r_x = ['r{}_x'.format(j) for j in range(1,6)]\n",
    "r_y = ['r{}_y'.format(j) for j in range(1,6)]\n",
    "d_x = ['d{}_x'.format(j) for j in range(1,6)]\n",
    "d_y = ['d{}_y'.format(j) for j in range(1,6)]\n",
    "\n",
    "r_in_d_base = pd.Series(0,index = full_df.index)\n",
    "d_in_r_base = pd.Series(0,index = full_df.index)\n",
    "\n",
    "for j in range(5):\n",
    "    rx = r_x[j]\n",
    "    ry = r_y[j]\n",
    "    dx = d_x[j]\n",
    "    dy = d_y[j]\n",
    "    r_in_d_base += full_df.loc[:,[rx,ry]].apply(lambda x: in_opponent_base(x = x[rx], y = x[ry], opponent = 'Radiant'), axis = 1)\n",
    "    d_in_r_base += full_df.loc[:,[dx,dy]].apply(lambda x: in_opponent_base(x = x[dx], y = x[dy], opponent = 'Dire'), axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features['r_in_d_base'] = r_in_d_base\n",
    "new_features['d_in_r_base'] = d_in_r_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_levels = ['d{}_level'.format(j) for j in range(1,6)] \n",
    "d_avg_level = full_df.loc[:,d_levels].mean(axis = 1)\n",
    "d_min_level = full_df.loc[:,d_levels].min(axis = 1)\n",
    "d_max_level = full_df.loc[:,d_levels].max(axis = 1)\n",
    "new_features['d_avg_level'] = d_avg_level\n",
    "new_features['d_min_level'] = d_min_level\n",
    "new_features['d_max_level'] = d_max_level\n",
    "\n",
    "\n",
    "r_levels = ['r{}_level'.format(j) for j in range(1,6)] \n",
    "r_avg_level = full_df.loc[:,r_levels].mean(axis = 1)\n",
    "r_min_level = full_df.loc[:,r_levels].min(axis = 1)\n",
    "r_max_level = full_df.loc[:,r_levels].max(axis = 1)\n",
    "new_features['r_avg_level'] = r_avg_level\n",
    "new_features['r_min_level'] = r_min_level\n",
    "new_features['r_max_level'] = r_max_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_teamfight = ['r{}_teamfight_participation'.format(j) for j in range(1,6)] \n",
    "for col in r_teamfight:\n",
    "    full_df[full_df[col] >1][col] = 1\n",
    "\n",
    "d_teamfight = ['d{}_teamfight_participation'.format(j) for j in range(1,6)] \n",
    "for col in d_teamfight:\n",
    "    full_df[full_df[col] >1][col] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_features.drop('target',axis=1).hist(figsize = (25,80),layout = (50,5), bins=20)\n",
    "#new_features.hist(figsize = (25,80),layout = (60,5), bins=20)\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create boolean features:\n",
    "\n",
    "`*_ability_level`\n",
    "`*_teamfight_participation`\n",
    "`*_kills`\n",
    "`*_assists`\n",
    "`*_deaths`\n",
    "`*_sen_placed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame()\n",
    "def create_boolean_features(cols):\n",
    "    for col in cols:\n",
    "        new_features['boolean_' + col] = np.where(new_features[col]==0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_cols = ['r_ability_level','d_ability_level','r_teamfight_participation',\n",
    "                'd_teamfight_participation','r_kills','d_kills',\n",
    "                'r_assists','d_assists','r_deaths','d_deaths','r_sen_placed',\n",
    "               'd_sen_placed']\n",
    "create_boolean_features(boolean_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take log of skewed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "col_for_log =  ['r_count_ability_use','r_max_hero_hit',\n",
    "                'r_damage_received','r_damage_dealt',\n",
    "                'r_max_mana','r_max_health',\n",
    "                'r_lh','r_health',\n",
    "     'r_gold', 'r_xp', 'r_stuns',\n",
    "    'd_count_ability_use', 'd_max_hero_hit',\n",
    "                'd_max_mana','d_max_health',\n",
    "                'd_damage_received','d_damage_dealt',\n",
    "               'd_health', 'd_stuns',\n",
    "     'd_gold', 'd_lh', 'd_xp']\n",
    "\n",
    "for col in col_for_log:\n",
    "    new_log_index = 'log_{}'.format(col)\n",
    "#     print(new_features[col].min())\n",
    "    new_features[col] = new_features[col].apply(lambda x: math.log(x+5))\n",
    "    \n",
    "#train_test_feat['chat_len'] = train_test_feat['chat_len'].apply(lambda x: math.log(x+5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions about categorical variables:\n",
    "* firstblood_claimed : categorical, binary\n",
    "* game_mode: categorical, non-ordinal --> needs to be converted to dummy variables\n",
    "* lobby_type: categorical, binary (value 7 chould be changes with 1)\n",
    "* hero_id: categorical, non-ordinal (too many levels)\n",
    "* level: categorical, ordinal (25 levels)\n",
    "* x,y are coordinates of players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine old and new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49675, 325)"
      ]
     },
     "execution_count": 855,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49675, 86)"
      ]
     },
     "execution_count": 764,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats = train_test_feat.merge(new_features, how='outer', left_index=True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats.drop(all_feats.columns[all_feats.isnull().any()],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 767,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_feats.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49675, 399)"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split `all_features` into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39675, 399)\n",
      "(10000, 399)\n"
     ]
    }
   ],
   "source": [
    "ind = train_X.shape[0]\n",
    "all_feats_train = all_feats.iloc[:ind,]\n",
    "all_feats_test = all_feats.iloc[ind:,:]\n",
    "print(all_feats_train.shape)\n",
    "print(all_feats_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chat_len</th>\n",
       "      <th>d1_ability_level</th>\n",
       "      <th>d1_assists</th>\n",
       "      <th>d1_camps_stacked</th>\n",
       "      <th>d1_count_ability_use</th>\n",
       "      <th>d1_creeps_stacked</th>\n",
       "      <th>d1_damage_dealt</th>\n",
       "      <th>d1_damage_received</th>\n",
       "      <th>d1_deaths</th>\n",
       "      <th>d1_denies</th>\n",
       "      <th>...</th>\n",
       "      <th>boolean_d_teamfight_participation</th>\n",
       "      <th>boolean_r_kills</th>\n",
       "      <th>boolean_d_kills</th>\n",
       "      <th>boolean_r_assists</th>\n",
       "      <th>boolean_d_assists</th>\n",
       "      <th>boolean_r_deaths</th>\n",
       "      <th>boolean_d_deaths</th>\n",
       "      <th>boolean_r_sen_placed</th>\n",
       "      <th>boolean_d_sen_placed</th>\n",
       "      <th>radiant_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000c270e25494c03d5c81036463fc45</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>94692</td>\n",
       "      <td>10497</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  chat_len  d1_ability_level  d1_assists  \\\n",
       "0000c270e25494c03d5c81036463fc45         3                11           1   \n",
       "\n",
       "                                  d1_camps_stacked  d1_count_ability_use  \\\n",
       "0000c270e25494c03d5c81036463fc45                 0                   111   \n",
       "\n",
       "                                  d1_creeps_stacked  d1_damage_dealt  \\\n",
       "0000c270e25494c03d5c81036463fc45                  0            94692   \n",
       "\n",
       "                                  d1_damage_received  d1_deaths  d1_denies  \\\n",
       "0000c270e25494c03d5c81036463fc45               10497          2         21   \n",
       "\n",
       "                                  ...  boolean_d_teamfight_participation  \\\n",
       "0000c270e25494c03d5c81036463fc45  ...                                  0   \n",
       "\n",
       "                                  boolean_r_kills  boolean_d_kills  \\\n",
       "0000c270e25494c03d5c81036463fc45                0                0   \n",
       "\n",
       "                                  boolean_r_assists  boolean_d_assists  \\\n",
       "0000c270e25494c03d5c81036463fc45                  0                  0   \n",
       "\n",
       "                                  boolean_r_deaths  boolean_d_deaths  \\\n",
       "0000c270e25494c03d5c81036463fc45                 0                 0   \n",
       "\n",
       "                                  boolean_r_sen_placed  boolean_d_sen_placed  \\\n",
       "0000c270e25494c03d5c81036463fc45                     0                     0   \n",
       "\n",
       "                                  radiant_win  \n",
       "0000c270e25494c03d5c81036463fc45         True  \n",
       "\n",
       "[1 rows x 400 columns]"
      ]
     },
     "execution_count": 777,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_feats_full = pd.concat([all_feats_train,y],axis=1)\n",
    "all_feats_full.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_feats_full.drop('radiant_win',axis=1),\n",
    "                                                    all_feats_full['radiant_win'], test_size=.3, \n",
    "                                                    stratify=all_feats_full['radiant_win'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27772, 399)"
      ]
     },
     "execution_count": 783,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27772,)"
      ]
     },
     "execution_count": 784,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "radiant_win    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 785,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelBinarizer, LabelEncoder\n",
    "from sklearn_pandas import DataFrameMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hero_ids = ['r{}_hero_id'.format(i) for i in range(1,6)] +['d{}_hero_id'.format(i) for i in range(1,6)]\n",
    "cat_feats = select_cols_n_distinct(all_feats_full,2,3)# + hero_ids\n",
    "cat_feats.remove('radiant_win')\n",
    "cat_feats.append('game_mode')\n",
    "\n",
    "#cat_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ord_feats = select_cols_n_distinct(all_feats,4,30)\n",
    "#ord_feats.remove('game_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feats = [feature for feature in all_feats_full.columns.values if feature not in cat_feats]\n",
    "num_feats.remove('radiant_win')\n",
    "#num_feats = [feature for feature in all_feats.columns.values if feature not in ord_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierCustom(BaseEstimator):\n",
    "    def __init__(self, C=1, n_estimators=200):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.C = C\n",
    "        \n",
    "        self.models = []\n",
    "        #self.boot = []\n",
    "        #self.feat_ids_by_tree = []\n",
    "    def fit(self, X, y):\n",
    "            #log reg\n",
    "            lr = LogisticRegression(C = self.C)\n",
    "            self.models.append(lr.fit(X,y))\n",
    "            \n",
    "            #Adaboost\n",
    "            ab = AdaBoostClassifier(n_estimators = 250, learning_rate = 1)\n",
    "            self.models.append(ab.fit(X,y))\n",
    "            \n",
    "            #lgbm\n",
    "            lgbm = LGBMClassifier(n_jobs=-1)\n",
    "            self.models.append(lgbm.fit(X,y))\n",
    "            return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        self.probs = [self.models[0].predict_proba(X)] #weight logistic regression double\n",
    "        for i in range(len(self.models)):\n",
    "            self.probs.append(self.models[i].predict_proba(X))\n",
    "        self.probs = np.array(self.probs)\n",
    "        self.averages = np.mean(self.probs, axis = 0)\n",
    "        return self.averages\n",
    "    \n",
    "    def predict(self,X):\n",
    "        self.predictions =  self.predict_proba(X) >=0.5 \n",
    "        return self.predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "class Columns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, names=None):\n",
    "        self.names = names\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.names]\n",
    "    \n",
    "    \n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"features\", FeatureUnion([\n",
    "        ('numeric', make_pipeline(Columns(names=num_feats),StandardScaler())),\n",
    "        ('categorical', make_pipeline(Columns(names=cat_feats),OneHotEncoder(sparse=False)))\n",
    "    ])),\n",
    "  #  ('PCA',PCA(n_components = 300,whiten=True)),\n",
    "    ('logreg', LogisticRegression(C=1))])\n",
    "    #('custom', ClassifierCustom(C = 0.95, n_estimators = 250))])\n",
    "    #('adaboost', AdaBoostClassifier(n_estimators = 150))])\n",
    "       #('lgbm', LGBMClassifier(n_jobs=-1,boost = 'gbdt',\n",
    "       #   feature_fraction= 0.05,\n",
    "       #   learning_rate= 0.005,\n",
    "       #     num_iterations = 500,\n",
    "       #   max_depth= -1,  \n",
    "       #   min_data_in_leaf = 150,\n",
    "       #   num_leaves = 64,\n",
    "       #   num_threads = -1,\n",
    "       #   verbosity= 1,\n",
    "       #   objective = 'binary'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 819,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_test_feat.columns.values).difference(set(all_feats_train.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('numeric', Pipeline(memory=None,\n",
       "     steps=[('columns', Columns(names=['chat_len', 'd1_ability_level', 'd1_assists', 'd1_camps_stacked', 'd1_count_ability_use', 'd1_creeps_stacked', 'd1_damage_dealt', 'd1_damage_received', 'd1_dea...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 820,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(all_feats_train,y)\n",
    "#pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9945391918003864\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994529800376085\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_test,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: So far, logreg with C = 0.95 does the best. The Custom ensemble is also close. PCA decreases both metrics and position on leaderboard; RF also decreased leaderboard position, over logreg (best so far).\\\n",
    "`cross_val_predict` gives ROC AUC 0.8132 for logistic regression. ROC AUC 0.8049 for lightGBM (untuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom classifier: logreg, Adaboost, lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lgbm = {\n",
    "    'lgbm__max_depth': [18],\n",
    "    'lgbm__learning_rate': [.01],\n",
    "    'lgbm__num_leaves': [4,8,16], #large will increase accuracy but may overfit\n",
    "    'lgbm__learning_rate': [0.005],\n",
    "    'lgbm__n_estimators': [40],\n",
    "    'lgbm__num_leaves': [6,8,12,16],\n",
    "    'lgbm__boosting_type' : ['gbdt'],\n",
    "    'lgbm__objective' : ['binary'],\n",
    "    'lgbm__random_state' : [501], # Updated from 'seed'\n",
    "    'lgbm__colsample_bytree' : [0.65, 0.66],\n",
    "    'lgbm__subsample' : [0.7,0.75],\n",
    "    'lgbm__reg_alpha' : [1,1.2],\n",
    "    'lgbm__reg_lambda' : [1,1.2,1.4],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_logreg = {\n",
    "    'logreg__C': [.9,0.95,1],\n",
    "    'PCA__n_components': [300]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_ab = {\n",
    "    'adaboost__n_estimators': [125,150,175],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_clf = GridSearchCV(pipe, param_grid_logreg, cv=5, iid=False)\n",
    "grid_clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PCA__n_components': 300, 'logreg__C': 1}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-bc68cac2a841>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grid search best: %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgrid_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"grid search best: %f\" % grid_clf.best_estimator_.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is doing better than other models. In grid search with best C = 0.9.\n",
    "\n",
    "PCA best around 300 (+-15).\n",
    "\n",
    "AdaBoost is doing more poorly; best `n_estimators` is 150 among `[50,100,150]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test_vals = all_feats_test.values\n",
    "y_test_pred = pipe.predict_proba(all_feats_test)[:, 1]\n",
    "\n",
    "df_submission = pd.DataFrame({'radiant_win_prob': y_test_pred}, \n",
    "                                 index=all_feats_test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.index.name='match_id_hash'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radiant_win_prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match_id_hash</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30cc2d778dca82f2edb568ce9b585caa</th>\n",
       "      <td>0.482591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70e5ba30f367cea48793b9003fab9d38</th>\n",
       "      <td>0.488290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4d9ef74d3a2025d79e9423105fd73d41</th>\n",
       "      <td>0.562868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  radiant_win_prob\n",
       "match_id_hash                                     \n",
       "30cc2d778dca82f2edb568ce9b585caa          0.482591\n",
       "70e5ba30f367cea48793b9003fab9d38          0.488290\n",
       "4d9ef74d3a2025d79e9423105fd73d41          0.562868"
      ]
     },
     "execution_count": 830,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to submission_2019-11-15_14-44-14.csv\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "submission_filename = 'submission_{}.csv'.format(\n",
    "    datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "df_submission.to_csv(submission_filename)\n",
    "print('Submission saved to {}'.format(submission_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not using this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_pred = cross_val_predict(pipe, \n",
    "                             X_train, \n",
    "                             y_train, \n",
    "                             cv=5,\n",
    "                             method=\"predict_proba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation AUC 0.8049\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross validation AUC {:.4f}\".format(roc_auc_score(y_train, cv_pred[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:751: DeprecationWarning: `make_column_transformer` now expects (transformer, columns) as input tuples instead of (columns, transformer). This has been introduced in v0.20.1. `make_column_transformer` will stop accepting the deprecated (columns, transformer) order in v0.22.\n",
      "  warnings.warn(message, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "\n",
    "preprocess = make_column_transformer(\n",
    "    (num_feats, StandardScaler()),\n",
    "    (cat_feats, OneHotEncoder()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = make_pipeline(\n",
    "    preprocess,\n",
    "   # StandardScaler(),\n",
    "    LGBMClassifier(n_jobs=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA + FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['game_time', 'game_mode', 'lobby_type', 'objectives_len', 'chat_len',\n",
       "       'r1_kills', 'r1_deaths', 'r1_assists', 'r1_denies', 'r1_gold',\n",
       "       ...\n",
       "       'r1_hero_idnorm', 'r2_hero_idnorm', 'r3_hero_idnorm', 'r4_hero_idnorm',\n",
       "       'r5_hero_idnorm', 'd1_hero_idnorm', 'd2_hero_idnorm', 'd3_hero_idnorm',\n",
       "       'd4_hero_idnorm', 'd5_hero_idnorm'],\n",
       "      dtype='object', length=316)"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22    31762\n",
       "4      3564\n",
       "23     2546\n",
       "3      1200\n",
       "2       408\n",
       "5       188\n",
       "12        5\n",
       "16        2\n",
       "Name: game_mode, dtype: int64"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df['game_mode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_mode_rad_win = full_df[full_df['radiant_win'] == True]['game_mode']\n",
    "game_mode_rad_lose = full_df[full_df['radiant_win'] == False]['game_mode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22    0.803659\n",
       "4     0.087871\n",
       "23    0.064007\n",
       "3     0.029434\n",
       "2     0.010708\n",
       "5     0.004177\n",
       "12    0.000096\n",
       "16    0.000048\n",
       "Name: game_mode, dtype: float64"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_mode_rad_win.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22    0.797125\n",
       "4     0.091994\n",
       "23    0.064354\n",
       "3     0.031142\n",
       "2     0.009815\n",
       "5     0.005358\n",
       "12    0.000159\n",
       "16    0.000053\n",
       "Name: game_mode, dtype: float64"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_mode_rad_lose.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7    0.683569\n",
      "0    0.316431\n",
      "Name: lobby_type, dtype: float64\n",
      "7    0.679771\n",
      "0    0.320229\n",
      "Name: lobby_type, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "lobby_type_rad_win = full_df[full_df['radiant_win'] == True]['lobby_type']\n",
    "lobby_type_rad_lose = full_df[full_df['radiant_win'] == False]['lobby_type']\n",
    "print(lobby_type_rad_win.value_counts(normalize=True))\n",
    "print(lobby_type_rad_lose.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectives_len_rad_win = full_df[full_df['radiant_win'] == True]['objectives_len']\n",
    "objectives_len_rad_lose = full_df[full_df['radiant_win'] == False]['objectives_len']\n",
    "#print(objectives_len_rad_win.value_counts(normalize=True))\n",
    "#print(objectives_len_rad_lose.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_rad_win = full_df[full_df['radiant_win']==True]\n",
    "full_rad_lose = full_df[full_df['radiant_win']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
